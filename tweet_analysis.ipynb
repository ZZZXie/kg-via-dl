{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mixed_user.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Russian  Trading Continues Even With Tightenin...\n",
       "1        Polygon includes $23 billion sports betting co...\n",
       "2        FTX Is Coming to Europe\\n\\nSentiment: Positive...\n",
       "3        Coinbase blocks 25,000  wallets tied to Russia...\n",
       "4        Crypto Exchange Binance To Launch New Payments...\n",
       "                               ...                        \n",
       "18239    Although BTC Outflow is used as a bullish sign...\n",
       "18240              We conducted research on Plus Token! \\n\n",
       "18241    We conduct research on Plus Token! They aggres...\n",
       "18242      Hey, we also did some research! It seems tha...\n",
       "18243                         Just setting up my Twitter. \n",
       "Name: text, Length: 18139, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\neelj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\neelj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, tokenizer, stopwords):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"\\[(.*?)\\]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\w+…|…\", \"\", text)\n",
    "    text = re.sub(r\"(?<=\\w)-(?=\\w)\", \" \", text)\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "\n",
    "    tokens = tokenizer(text)\n",
    "    tokens = [t for t in tokens if not t in stopwords]\n",
    "    tokens = [\"\" if t.isdigit() else t for t in tokens]\n",
    "    tokens = [t for t in tokens if len(t) > 1]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['text'].map(lambda x: clean_text(x, word_tokenize, stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_lists = df['tokens'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=tokenized_lists, vector_size=100, workers=1, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(tokenized_lists, model):\n",
    "    features = []\n",
    "    for tokens in tokenized_lists:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in model.wv:\n",
    "                try:\n",
    "                    vectors.append(model.wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18139, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_lists = vectorize(tokenized_lists, model)\n",
    "len(vectorized_lists), len(vectorized_lists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbkmeans_clusters(X, k, mb, print_silhouette_values):\n",
    "    km = MiniBatchKMeans(n_clusters=k, batch_size=mb).fit(X)\n",
    "    print(f\"For n_clusters = {k}\")\n",
    "    print(f\"Silhouette coefficient: {silhouette_score(X, km.labels_):0.2f}\")\n",
    "    print(f\"Inertia:{km.inertia_}\")\n",
    "\n",
    "    if print_silhouette_values:\n",
    "        sample_silhouette_values = silhouette_samples(X, km.labels_)\n",
    "        print(f\"Silhouette values:\")\n",
    "        silhouette_values = []\n",
    "        for i in range(k):\n",
    "            cluster_silhouette_values = sample_silhouette_values[km.labels_ == i]\n",
    "            silhouette_values.append(\n",
    "                (\n",
    "                    i,\n",
    "                    cluster_silhouette_values.shape[0],\n",
    "                    cluster_silhouette_values.mean(),\n",
    "                    cluster_silhouette_values.min(),\n",
    "                    cluster_silhouette_values.max(),\n",
    "                )\n",
    "            )\n",
    "        silhouette_values = sorted(\n",
    "            silhouette_values, key=lambda tup: tup[2], reverse=True\n",
    "        )\n",
    "        for s in silhouette_values:\n",
    "            print(\n",
    "                f\"    Cluster {s[0]}: Size:{s[1]} | Avg:{s[2]:.2f} | Min:{s[3]:.2f} | Max: {s[4]:.2f}\"\n",
    "            )\n",
    "    return km, km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 10\n",
      "Silhouette coefficient: 0.14\n",
      "Inertia:9575.272598783751\n",
      "Silhouette values:\n",
      "    Cluster 7: Size:415 | Avg:0.45 | Min:0.00 | Max: 0.63\n",
      "    Cluster 9: Size:289 | Avg:0.22 | Min:-0.11 | Max: 0.48\n",
      "    Cluster 4: Size:4416 | Avg:0.20 | Min:-0.04 | Max: 0.43\n",
      "    Cluster 3: Size:2754 | Avg:0.17 | Min:-0.08 | Max: 0.40\n",
      "    Cluster 1: Size:1568 | Avg:0.16 | Min:-0.04 | Max: 0.37\n",
      "    Cluster 2: Size:1175 | Avg:0.14 | Min:-0.11 | Max: 0.38\n",
      "    Cluster 8: Size:876 | Avg:0.11 | Min:-0.15 | Max: 0.34\n",
      "    Cluster 5: Size:1834 | Avg:0.10 | Min:-0.16 | Max: 0.35\n",
      "    Cluster 0: Size:3292 | Avg:0.09 | Min:-0.19 | Max: 0.32\n",
      "    Cluster 6: Size:1520 | Avg:0.01 | Min:-0.25 | Max: 0.29\n"
     ]
    }
   ],
   "source": [
    "clustering, cluster_labels = mbkmeans_clusters(X=vectorized_lists, k=10, mb=500, print_silhouette_values=True)\n",
    "df_clusters = pd.DataFrame({\"text\": df['text'], \"tokens\": [\" \".join(text) for text in tokenized_lists], \"cluster\": cluster_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russian  Trading Continues Even With Tightenin...</td>\n",
       "      <td>russian trading continues even tightening sanc...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polygon includes $23 billion sports betting co...</td>\n",
       "      <td>polygon includes billion sports betting compan...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FTX Is Coming to Europe\\n\\nSentiment: Positive...</td>\n",
       "      <td>ftx coming europe sentiment positive cryptocur...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coinbase blocks 25,000  wallets tied to Russia...</td>\n",
       "      <td>coinbase blocks wallets tied russians suspecte...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crypto Exchange Binance To Launch New Payments...</td>\n",
       "      <td>crypto exchange binance launch new payments te...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18239</th>\n",
       "      <td>Although BTC Outflow is used as a bullish sign...</td>\n",
       "      <td>although btc outflow used bullish signal look ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18240</th>\n",
       "      <td>We conducted research on Plus Token! \\n</td>\n",
       "      <td>conducted research plus token</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18241</th>\n",
       "      <td>We conduct research on Plus Token! They aggres...</td>\n",
       "      <td>conduct research plus token aggressively used ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18242</th>\n",
       "      <td>Hey, we also did some research! It seems tha...</td>\n",
       "      <td>hey also research seems 3lnmrygaq8hdsfjxvpmsna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18243</th>\n",
       "      <td>Just setting up my Twitter.</td>\n",
       "      <td>setting twitter</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18139 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Russian  Trading Continues Even With Tightenin...   \n",
       "1      Polygon includes $23 billion sports betting co...   \n",
       "2      FTX Is Coming to Europe\\n\\nSentiment: Positive...   \n",
       "3      Coinbase blocks 25,000  wallets tied to Russia...   \n",
       "4      Crypto Exchange Binance To Launch New Payments...   \n",
       "...                                                  ...   \n",
       "18239  Although BTC Outflow is used as a bullish sign...   \n",
       "18240            We conducted research on Plus Token! \\n   \n",
       "18241  We conduct research on Plus Token! They aggres...   \n",
       "18242    Hey, we also did some research! It seems tha...   \n",
       "18243                       Just setting up my Twitter.    \n",
       "\n",
       "                                                  tokens  cluster  \n",
       "0      russian trading continues even tightening sanc...        4  \n",
       "1      polygon includes billion sports betting compan...        3  \n",
       "2      ftx coming europe sentiment positive cryptocur...        6  \n",
       "3      coinbase blocks wallets tied russians suspecte...        4  \n",
       "4      crypto exchange binance launch new payments te...        3  \n",
       "...                                                  ...      ...  \n",
       "18239  although btc outflow used bullish signal look ...        0  \n",
       "18240                      conducted research plus token        3  \n",
       "18241  conduct research plus token aggressively used ...        3  \n",
       "18242  hey also research seems 3lnmrygaq8hdsfjxvpmsna...        0  \n",
       "18243                                    setting twitter        6  \n",
       "\n",
       "[18139 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most representative terms per cluster (based on centroids):\n",
      "Cluster 0: morning gained doubled broader climbed \n",
      "Cluster 1: washington authorities legislation nations spain \n",
      "Cluster 2: mainnet harmony chainlink successfully protocols \n",
      "Cluster 3: space organization version ticketing esports \n",
      "Cluster 4: millennials citing reports wealthy debt \n",
      "Cluster 5: dropped drops increased hour surged \n",
      "Cluster 6: boss dimon director citadel facebook \n",
      "Cluster 7: chivo salvadoran volcanic tourism adopt \n",
      "Cluster 8: nigeria americas switzerland cbdc switzerlands \n",
      "Cluster 9: cofounder creator alexis ohanian markus \n"
     ]
    }
   ],
   "source": [
    "print(\"Most representative terms per cluster (based on centroids):\")\n",
    "for i in range(10):\n",
    "    tokens_per_cluster = \"\"\n",
    "    most_representative = model.wv.most_similar(positive=[clustering.cluster_centers_[i]], topn=5)\n",
    "    for t in most_representative:\n",
    "        tokens_per_cluster += f\"{t[0]} \"\n",
    "    print(f\"Cluster {i}: {tokens_per_cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
