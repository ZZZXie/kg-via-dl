{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30ecd2b1-6a36-4f25-8716-9eb5dc702b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import json\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90b3f5bb-589b-483b-b254-dd92cfe3e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "whitepaper_names = ['avalanche.txt', 'binance_coin.txt', 'bitcoin.txt', 'cardano.txt', \n",
    "               'ethereum.txt', 'polkadot.txt', 'ripple.txt', 'shiba_inu.txt', \n",
    "               'solana.txt', 'terra.txt', 'tether.txt', 'usdcoin.txt', \n",
    "               'wrapped_tokens.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d039b3f8-293d-4165-946f-6bded7bde62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in most frequent tokens\n",
    "with open('word_freq.json') as f:\n",
    "    word_freq_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4533728-422c-417f-940a-ca5c812cf1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "\n",
    "def tokenization(text):\n",
    "    text = text.strip()\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96c71a95-b6dc-4ec2-82e3-0c53b1760b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5366\n"
     ]
    }
   ],
   "source": [
    "def split_sentences(text):\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "def tokenize_sentences(sentences):\n",
    "    tokens = []\n",
    "    for sentence in sentences:\n",
    "        tokens.append(lemmatizer(remove_stopwords(tokenization(remove_punct(sentence).lower()))))\n",
    "    return tokens\n",
    "\n",
    "res = []\n",
    "for paper in whitepaper_names: \n",
    "    with open(paper) as f:\n",
    "        data = f.read()\n",
    "        sentences = split_sentences(data)\n",
    "        res += tokenize_sentences(sentences)\n",
    "        \n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "69dcda2e-c626-4ea9-8215-213eb221a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_model = gensim.models.Word2Vec(res, window=10, min_count=5, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3b1b8fc1-8552-45a0-8fa8-41f43a765b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ethereum', 0.9996058344841003),\n",
       " ('account', 0.9993658065795898),\n",
       " ('currency', 0.9993055462837219),\n",
       " ('blockchain', 0.9992681741714478),\n",
       " ('miner', 0.9992648363113403),\n",
       " ('contract', 0.9992493391036987),\n",
       " ('provide', 0.9992296099662781),\n",
       " ('transaction', 0.9991385340690613),\n",
       " ('user', 0.9991267323493958),\n",
       " ('would', 0.9990862011909485)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv.most_similar('bitcoin', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62415a55-a129-45ef-a7a6-36a24ff7a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note this is manually created\n",
    "# current issue: two word phrases aren't captured \n",
    "ontology_classes = ['cryptocurrency', 'person', 'protocol', 'electroniccoin', 'distributionscheme', \n",
    "                    'repository', 'organization', 'version', 'tradingplatform', 'wallet', 'algorithm', \n",
    "                    'cryptographichashfunction', 'protectionscheme', 'hashfunction', 'posscheme',\n",
    "                    'poascheme', 'powscheme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9352b03-ec93-4f8e-97c4-8ea60d1d2938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cryptocurrency', 'person', 'protocol', 'organization', 'version', 'wallet', 'algorithm']\n",
      "['electroniccoin', 'distributionscheme', 'repository', 'tradingplatform', 'cryptographichashfunction', 'protectionscheme', 'hashfunction', 'posscheme', 'poascheme', 'powscheme']\n"
     ]
    }
   ],
   "source": [
    "in_vocab = []\n",
    "oo_vocab = []\n",
    "for class_name in ontology_classes:\n",
    "    if class_name in gensim_model.wv:\n",
    "        in_vocab.append(class_name)\n",
    "    else:\n",
    "        oo_vocab.append(class_name)\n",
    "print(in_vocab)\n",
    "print(oo_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "89998bfa-57b9-4a53-96f5-1fa909a26ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# now we find alternative names for the ontology:\n",
    "# electroniccoin -> coin\n",
    "print('coin' in gensim_model.wv)\n",
    "\n",
    "# distributionscheme -> distribution\n",
    "print('distribution' in gensim_model.wv)\n",
    "\n",
    "# repository? -> drop from ontology for now\n",
    "\n",
    "# tradingplatform -> platform\n",
    "print('platform' in gensim_model.wv)\n",
    "\n",
    "# cryptographichashfunction -> hash \n",
    "print('hash' in gensim_model.wv)\n",
    "\n",
    "# protectionscheme -> protection\n",
    "print('protection' in gensim_model.wv)\n",
    "\n",
    "# posscheme\n",
    "# poascheme\n",
    "# powscheme\n",
    "# convert all to -> po_ (ex. poa, pos, pow)\n",
    "print('poa' in gensim_model.wv) #drop poa\n",
    "print('state' in gensim_model.wv) #drop pos\n",
    "print('pow' in gensim_model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a534a744-c18e-4fe5-b11b-c4202f151951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cryptocurrency', 'person', 'protocol', 'organization', 'version', 'wallet', 'algorithm', 'coin', 'distribution', 'platform', 'hash', 'protection', 'pow']\n"
     ]
    }
   ],
   "source": [
    "new_ontology_classes = in_vocab + ['coin', 'distribution', 'platform', 'hash', 'protection', 'pow']\n",
    "print(new_ontology_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a43d69bd-5bf3-49f8-a002-c86827007579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "[('bitcoin', 0.9993055462837219), ('fiat', 0.998906135559082), ('account', 0.9988996982574463), ('ethereum', 0.9988289475440979), ('exchange', 0.9988181591033936), ('token', 0.9987944960594177), ('user', 0.9987197518348694), ('contract', 0.9987178444862366), ('asset', 0.998607873916626), ('decentralized', 0.9985966086387634)]\n"
     ]
    }
   ],
   "source": [
    "print(word_freq_dict['currency'])\n",
    "print(gensim_model.wv.most_similar('currency', topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c813b104-fca2-40b8-a630-383e69914a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "7634.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05763688760806916"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def match_finder(token, remaining_depth, neighbor_thresh=10):\n",
    "    if token in new_ontology_classes:   \n",
    "        return True\n",
    "    else:\n",
    "        if remaining_depth >= 0:\n",
    "            neighbors = gensim_model.wv.most_similar(token, topn=neighbor_thresh)\n",
    "            status = False\n",
    "            for neighbor, _ in neighbors:\n",
    "                if match_finder(neighbor, remaining_depth-1, neighbor_thresh):\n",
    "                    status = True\n",
    "            return status\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "\n",
    "def count_matches(freq_thresh=30, neighbor_thresh = 10, depth=3):\n",
    "    total = 0.0\n",
    "    found = 0\n",
    "    for token, freq in word_freq_dict.items():\n",
    "        if freq >= freq_thresh and token in gensim_model.wv:\n",
    "            if match_finder(token, depth, neighbor_thresh):    \n",
    "                found += 1\n",
    "        total += 1\n",
    "    print(found)\n",
    "    print(total)\n",
    "    return found/total\n",
    "\n",
    "count_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9a9a3bf1-515a-44a1-9941-ca5d84173f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "7634.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.009693476552266178"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matches(100, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e14536-a0a8-4440-bb36-4edc824e3345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
